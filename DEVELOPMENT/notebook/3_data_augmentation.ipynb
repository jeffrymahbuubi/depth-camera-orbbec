{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import numpy as np\n",
    "import seedir as sd\n",
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Synthetic Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting into Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir = r'D:\\RESEARCH ASSISTANT\\6. Depth Camera\\CODE\\Orbbec Gemini 2XL\\REMOTE\\DEVELOPMENT\\notebook\\DATA\\20250402\\video\\rgb'\n",
    "save_dir = os.path.join(os.path.dirname(video_dir), 'split_rgb')\n",
    "\n",
    "# Define subfolders\n",
    "train_dir = os.path.join(save_dir, 'train')\n",
    "val_dir = os.path.join(save_dir, 'val')\n",
    "\n",
    "# Create directory structure\n",
    "for target_dir in [train_dir, val_dir]:\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Loop over each class folder\n",
    "for class_name in os.listdir(video_dir):\n",
    "    class_path = os.path.join(video_dir, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    # List all .npy files in the class\n",
    "    npy_files = glob.glob(os.path.join(class_path, '*.npy'))\n",
    "\n",
    "    # Split using sklearn\n",
    "    train_files, val_files = train_test_split(npy_files, test_size=0.33, random_state=42)\n",
    "\n",
    "    # Destination subfolders\n",
    "    train_class_dir = os.path.join(train_dir, class_name)\n",
    "    val_class_dir = os.path.join(val_dir, class_name)\n",
    "    os.makedirs(train_class_dir, exist_ok=True)\n",
    "    os.makedirs(val_class_dir, exist_ok=True)\n",
    "\n",
    "    # Copy files to train\n",
    "    for f in train_files:\n",
    "        shutil.copy2(f, os.path.join(train_class_dir, os.path.basename(f)))\n",
    "\n",
    "    # Copy files to val\n",
    "    for f in val_files:\n",
    "        shutil.copy2(f, os.path.join(val_class_dir, os.path.basename(f)))\n",
    "\n",
    "print(f\"Dataset split complete. Saved to: {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Generation\n",
    "\n",
    "1. Use `albumentations` library to generate data of `train` üìÅ\n",
    "2. The data shape is `(T, C, H, W)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing classes:  20%|‚ñà‚ñà        | 1/5 [00:06<00:24,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hand_Close] now has 20 files in D:\\RESEARCH ASSISTANT\\6. Depth Camera\\CODE\\Orbbec Gemini 2XL\\REMOTE\\DEVELOPMENT\\notebook\\DATA\\20250402\\video\\split_rgb\\train_aug\\Hand_Close\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing classes:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:12<00:18,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hand_Open] now has 20 files in D:\\RESEARCH ASSISTANT\\6. Depth Camera\\CODE\\Orbbec Gemini 2XL\\REMOTE\\DEVELOPMENT\\notebook\\DATA\\20250402\\video\\split_rgb\\train_aug\\Hand_Open\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing classes:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:18<00:12,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Hook_Hand] now has 20 files in D:\\RESEARCH ASSISTANT\\6. Depth Camera\\CODE\\Orbbec Gemini 2XL\\REMOTE\\DEVELOPMENT\\notebook\\DATA\\20250402\\video\\split_rgb\\train_aug\\Hook_Hand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing classes:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:24<00:05,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Intrinsic_Plan] now has 20 files in D:\\RESEARCH ASSISTANT\\6. Depth Camera\\CODE\\Orbbec Gemini 2XL\\REMOTE\\DEVELOPMENT\\notebook\\DATA\\20250402\\video\\split_rgb\\train_aug\\Intrinsic_Plan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing classes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:29<00:00,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Straight_Fist] now has 20 files in D:\\RESEARCH ASSISTANT\\6. Depth Camera\\CODE\\Orbbec Gemini 2XL\\REMOTE\\DEVELOPMENT\\notebook\\DATA\\20250402\\video\\split_rgb\\train_aug\\Straight_Fist\n",
      "‚úÖ Done creating fresh synthetic training videos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "\n",
    "video_dir       = r'D:\\RESEARCH ASSISTANT\\6. Depth Camera\\CODE\\Orbbec Gemini 2XL\\REMOTE\\DEVELOPMENT\\notebook\\DATA\\20250402\\video'\n",
    "train_dir       = os.path.join(video_dir, \"split_rgb\", \"train\")\n",
    "aug_dir         = os.path.join(os.path.dirname(train_dir), \"train_aug\")\n",
    "n_applications  = 9   # how many aug variants per original\n",
    "\n",
    "transform = A.ReplayCompose([\n",
    "    A.ElasticTransform(alpha=0.5, p=0.5),\n",
    "    A.ShiftScaleRotate(scale_limit=0.05, rotate_limit=10, p=0.5),\n",
    "    A.RGBShift(r_shift_limit=50, g_shift_limit=50, b_shift_limit=50, p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "    A.CLAHE(p=0.5),\n",
    "    A.PixelDropout(drop_value=0, dropout_prob=0.01, p=0.5),\n",
    "    A.PixelDropout(drop_value=255, dropout_prob=0.01, p=0.5),\n",
    "    A.Blur(blur_limit=(2, 4), p=0.5)\n",
    "])\n",
    "\n",
    "def augment_numpy_video(arr: np.ndarray):\n",
    "    T, C, H, W = arr.shape\n",
    "    out_frames, replay = [], None\n",
    "\n",
    "    for t in range(T):\n",
    "        frame = arr[t].transpose(1, 2, 0).astype(\"uint8\")\n",
    "        if t == 0:\n",
    "            data   = transform(image=frame)\n",
    "            new    = data[\"image\"]\n",
    "            replay = data[\"replay\"]\n",
    "        else:\n",
    "            new = A.ReplayCompose.replay(replay, image=frame)[\"image\"]\n",
    "        out_frames.append(new)\n",
    "\n",
    "    return np.stack([f.transpose(2, 0, 1) for f in out_frames], axis=0)\n",
    "\n",
    "# Walk each class folder\n",
    "for cls in tqdm(os.listdir(train_dir), desc=\"Processing classes\"):\n",
    "    src_cls_dir = os.path.join(train_dir, cls)\n",
    "    dst_cls_dir = os.path.join(aug_dir, cls)\n",
    "\n",
    "    # 1) Clear out any previous augmented files\n",
    "    if os.path.isdir(dst_cls_dir):\n",
    "        for old in os.listdir(dst_cls_dir):\n",
    "            if \"_aug\" in old or old.endswith(\"_orig.npy\"):\n",
    "                os.remove(os.path.join(dst_cls_dir, old))\n",
    "    else:\n",
    "        os.makedirs(dst_cls_dir, exist_ok=True)\n",
    "\n",
    "    # 2) Generate fresh augmentations\n",
    "    file_list = [f for f in os.listdir(src_cls_dir) if f.endswith(\".npy\")]\n",
    "    for fname in tqdm(file_list, desc=f\"Augmenting {cls}\", leave=False):\n",
    "        src_path = os.path.join(src_cls_dir, fname)\n",
    "        base, _  = os.path.splitext(fname)\n",
    "\n",
    "        arr = np.load(src_path)\n",
    "\n",
    "        # Save a base copy\n",
    "        orig_path = os.path.join(dst_cls_dir, f\"{base}_orig.npy\")\n",
    "        np.save(orig_path, arr)\n",
    "\n",
    "        # Generate N augmentations\n",
    "        for i in range(1, n_applications + 1):\n",
    "            aug_arr = augment_numpy_video(arr)\n",
    "            out_path = os.path.join(dst_cls_dir, f\"{base}_aug{i}.npy\")\n",
    "            np.save(out_path, aug_arr)\n",
    "\n",
    "    print(f\"[{cls}] now has {len(os.listdir(dst_cls_dir))} files in {dst_cls_dir}\")\n",
    "\n",
    "print(\"‚úÖ Done creating fresh synthetic training videos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded D:\\RESEARCH ASSISTANT\\6. Depth Camera\\CODE\\Orbbec Gemini 2XL\\REMOTE\\DEVELOPMENT\\notebook\\DATA\\20250402\\video\\split_rgb\\train_aug\\Hand_Close\\recording_1_Hand_Close_aug1.npy, shape: (16, 3, 300, 300)\n"
     ]
    }
   ],
   "source": [
    "import rerun.blueprint as rrb\n",
    "import rerun as rr\n",
    "\n",
    "def rerun_visualization_from_npy(npy_path: str):\n",
    "    # Load the .npy video: shape (T, C, H, W)\n",
    "    video_array = np.load(npy_path)\n",
    "    print(f\"Loaded {npy_path}, shape: {video_array.shape}\")\n",
    "\n",
    "    stream = rr.new_recording(\"rerun_augmented_video\", spawn=True)\n",
    "\n",
    "    # Configure layout\n",
    "    blueprint = rrb.Blueprint(\n",
    "        rrb.Grid(\n",
    "            rrb.Vertical(\n",
    "                rrb.Spatial2DView(origin=\"/color_image\"),\n",
    "            ),\n",
    "        ),\n",
    "        collapse_panels=True,\n",
    "    )\n",
    "\n",
    "    # Log each frame\n",
    "    for idx, frame in enumerate(video_array):\n",
    "        # Convert (C, H, W) to (H, W, C) for display\n",
    "        image = np.transpose(frame, (1, 2, 0)).astype(np.uint8)\n",
    "        stream.set_time_sequence(\"frame\", idx)\n",
    "        stream.log(\"color_image\", rr.Image(image))\n",
    "\n",
    "    stream.send_blueprint(blueprint)\n",
    "\n",
    "classes = ['Hand_Close', 'Hand_Open', 'Hook_Hand', 'Intrinsic_Plan', 'Straight_Fist']\n",
    "target_dir = os.path.join(aug_dir, classes[0])\n",
    "\n",
    "# Files with _aug{i} suffix\n",
    "augmented_files = glob.glob(os.path.join(target_dir, '*_aug*.npy'))\n",
    "\n",
    "# Visualize first one\n",
    "rerun_visualization_from_npy(augmented_files[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
